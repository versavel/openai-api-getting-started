{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f977ebe3-1e5b-4e1c-bb1b-1869e7760e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d3c992-edea-4a40-aa17-f6544f3b6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key', 'r') as file:\n",
    "    openai_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1237e1b2-9891-4c24-be53-fb8cffa803ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7cffa3-57fd-4c4d-8ac2-8d95b734f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import Model, ModelDeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4746b8b3-1f55-4075-9599-5f9d7d7f34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b5edd0-8a62-409e-8006-880d8390e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.pagination.SyncPage[Model]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c91f725-0dbd-4152-a946-cea6d939a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-vision-preview\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-16k-0613\n"
     ]
    }
   ],
   "source": [
    "for k in models:\n",
    "    if \"gpt\" in k.id:\n",
    "        print(k.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd733f5c-640c-4d29-a171-a673c9f34a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-4-turbo-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b90907-95ee-4f6f-b28b-06fd3fb61765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e19de70-ed80-4e66-b0e9-7e68914c9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "step 1: extract keypoints and descriptors from all images\n",
    "step 2: find matches between all images\n",
    "step 3: select a reference image\n",
    "step 4: begin adding the other images together with the reference image by\n",
    "  first finding a transformation between them\n",
    "  and then blending the images together\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628fbb66-fae7-488c-897f-5e6173863039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a panorama involves stitching multiple images together to form a single, wide photograph. This process can be complex, but OpenCV provides tools that make it easier. Below is a Python script that follows your specified algorithm to create a panorama from a set of images. This script assumes you have OpenCV and NumPy installed. If not, you can install them using pip:\n",
      "\n",
      "```bash\n",
      "pip install opencv-python numpy\n",
      "```\n",
      "\n",
      "Here's the script:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import numpy as np\n",
      "import os\n",
      "\n",
      "def load_images_from_folder(folder):\n",
      "    images = []\n",
      "    for filename in os.listdir(folder):\n",
      "        img = cv2.imread(os.path.join(folder, filename))\n",
      "        if img is not None:\n",
      "            images.append(img)\n",
      "    return images\n",
      "\n",
      "def find_keypoints_and_descriptors(images):\n",
      "    sift = cv2.SIFT_create()\n",
      "    keypoints_and_descriptors = []\n",
      "    for img in images:\n",
      "        kp, des = sift.detectAndCompute(img, None)\n",
      "        keypoints_and_descriptors.append((kp, des))\n",
      "    return keypoints_and_descriptors\n",
      "\n",
      "def find_matches(descriptors):\n",
      "    bf = cv2.BFMatcher()\n",
      "    matches = []\n",
      "    for i in range(len(descriptors)):\n",
      "        for j in range(i + 1, len(descriptors)):\n",
      "            matches.append(bf.knnMatch(descriptors[i][1], descriptors[j][1], k=2))\n",
      "    return matches\n",
      "\n",
      "def filter_matches(matches, ratio=0.75):\n",
      "    good_matches = []\n",
      "    for match in matches:\n",
      "        filtered = []\n",
      "        for m, n in match:\n",
      "            if m.distance < ratio * n.distance:\n",
      "                filtered.append(m)\n",
      "        good_matches.append(filtered)\n",
      "    return good_matches\n",
      "\n",
      "def stitch_images(images, keypoints, matches):\n",
      "    # Assuming the first image is the reference image\n",
      "    reference_img = images[0]\n",
      "    kp1, _ = keypoints[0]\n",
      "    for i in range(1, len(images)):\n",
      "        _, des1 = keypoints[i-1]\n",
      "        kp2, des2 = keypoints[i]\n",
      "        # Use the matches to find the homography\n",
      "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches[i-1]]).reshape(-1, 1, 2)\n",
      "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches[i-1]]).reshape(-1, 1, 2)\n",
      "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
      "        # Warp the current image to fit the reference image\n",
      "        h, w, _ = images[i].shape\n",
      "        img_warped = cv2.warpPerspective(images[i], M, (w, h))\n",
      "        # Blend the images together (simple overlay for demonstration)\n",
      "        reference_img = cv2.addWeighted(reference_img, 0.5, img_warped, 0.5, 0)\n",
      "    return reference_img\n",
      "\n",
      "def create_panorama(folder):\n",
      "    images = load_images_from_folder(folder)\n",
      "    keypoints_and_descriptors = find_keypoints_and_descriptors(images)\n",
      "    descriptors = [x[1] for x in keypoints_and_descriptors]\n",
      "    matches = find_matches(descriptors)\n",
      "    good_matches = filter_matches(matches)\n",
      "    panorama = stitch_images(images, keypoints_and_descriptors, good_matches)\n",
      "    cv2.imwrite('panorama.jpg', panorama)\n",
      "    cv2.imshow('Panorama', panorama)\n",
      "    cv2.waitKey(0)\n",
      "    cv2.destroyAllWindows()\n",
      "\n",
      "# Replace 'path_to_images' with the path to your images\n",
      "create_panorama('path_to_images')\n",
      "```\n",
      "\n",
      "This script is a simplified approach to creating panoramas and includes the following steps:\n",
      "\n",
      "1. **Loading Images**: It loads all images from a specified folder.\n",
      "2. **Finding Keypoints and Descriptors**: It uses SIFT to find keypoints and descriptors in each image.\n",
      "3. **Finding Matches**: It matches descriptors between all pairs of images using the brute-force matcher.\n",
      "4. **Filtering Matches**: It filters out poor matches based on the distance ratio test.\n",
      "5. **Stitching Images**: It stitches images together by finding a homography between matched keypoints and warping images to align with the reference image. This script uses a simple blending method (averaging) to combine images, which might not be ideal for all scenarios.\n",
      "\n",
      "Note: This script is a basic implementation and might not handle all edge cases or produce perfect panoramas, especially with complex scenes or images with very little overlap. Advanced techniques, such as multi-band blending and feature-based alignment, can significantly improve the quality of the resulting panorama.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "I'm coding in python and using the OpenCV library. Give me a python script to build panoramas using the following algorithm:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa09e5-a48d-49ba-8e6c-a782d1077183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
