{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f977ebe3-1e5b-4e1c-bb1b-1869e7760e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d3c992-edea-4a40-aa17-f6544f3b6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key', 'r') as file:\n",
    "    openai_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1237e1b2-9891-4c24-be53-fb8cffa803ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7cffa3-57fd-4c4d-8ac2-8d95b734f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import Model, ModelDeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4746b8b3-1f55-4075-9599-5f9d7d7f34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b5edd0-8a62-409e-8006-880d8390e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.pagination.SyncPage[Model]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c91f725-0dbd-4152-a946-cea6d939a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-vision-preview\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-16k-0613\n"
     ]
    }
   ],
   "source": [
    "for k in models:\n",
    "    if \"gpt\" in k.id:\n",
    "        print(k.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd733f5c-640c-4d29-a171-a673c9f34a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-4-turbo-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b90907-95ee-4f6f-b28b-06fd3fb61765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e19de70-ed80-4e66-b0e9-7e68914c9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "step 1: extract keypoints and descriptors from all images\n",
    "step 2: find matches between all images\n",
    "step 3: select a reference image\n",
    "step 4: begin adding the other images together with the reference image by\n",
    "  first finding a transformation between them\n",
    "  and then blending the images together\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628fbb66-fae7-488c-897f-5e6173863039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a panorama from multiple images involves several steps, including feature detection, feature matching, estimating a homography matrix, and finally stitching and blending the images together. Below is a Python script that demonstrates these steps using OpenCV to stitch 4 images into a panorama. This script assumes you have OpenCV installed (`pip install opencv-python`) and your images are named `image1.jpg`, `image2.jpg`, `image3.jpg`, and `image4.jpg`.\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "# Function to stitch images\n",
      "def stitch_images(images):\n",
      "    # Step 1: Extract keypoints and descriptors from all images\n",
      "    sift = cv2.SIFT_create()\n",
      "    keypoints_descriptors = [sift.detectAndCompute(image, None) for image in images]\n",
      "    \n",
      "    # Step 2: Find matches between all images\n",
      "    # Using FLANN based matcher\n",
      "    FLANN_INDEX_KDTREE = 1\n",
      "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
      "    search_params = dict(checks=50)\n",
      "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
      "    \n",
      "    matches = []\n",
      "    for i in range(len(keypoints_descriptors) - 1):\n",
      "        matches.append(flann.knnMatch(keypoints_descriptors[i][1], keypoints_descriptors[i+1][1], k=2))\n",
      "    \n",
      "    # Filter matches using the Lowe's ratio test\n",
      "    good_matches = []\n",
      "    for match in matches:\n",
      "        good = []\n",
      "        for m, n in match:\n",
      "            if m.distance < 0.7*n.distance:\n",
      "                good.append(m)\n",
      "        good_matches.append(good)\n",
      "    \n",
      "    # Step 3: Select a reference image\n",
      "    # In this case, we'll use the first image as the reference\n",
      "    reference_idx = 0\n",
      "    reference_image = images[reference_idx]\n",
      "    reference_kp, reference_desc = keypoints_descriptors[reference_idx]\n",
      "    \n",
      "    # Step 4: Begin adding the other images together with the reference image\n",
      "    panorama = reference_image\n",
      "    for i, (kp, desc) in enumerate(keypoints_descriptors):\n",
      "        if i == reference_idx:\n",
      "            continue\n",
      "        \n",
      "        # Find homography\n",
      "        src_pts = np.float32([reference_kp[m.queryIdx].pt for m in good_matches[i-1]]).reshape(-1,1,2)\n",
      "        dst_pts = np.float32([kp[m.trainIdx].pt for m in good_matches[i-1]]).reshape(-1,1,2)\n",
      "        \n",
      "        M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
      "        \n",
      "        # Warp and blend the images together\n",
      "        w, h, _ = panorama.shape\n",
      "        img_warped = cv2.warpPerspective(images[i], M, (h, w))\n",
      "        \n",
      "        # Simple blending by averaging\n",
      "        # Note: For better results consider using more sophisticated blending techniques\n",
      "        panorama = np.where(panorama > 0, 0.5 * panorama + 0.5 * img_warped, img_warped)\n",
      "    \n",
      "    return panorama\n",
      "\n",
      "# Load images\n",
      "image_files = ['image1.jpg', 'image2.jpg', 'image3.jpg', 'image4.jpg']\n",
      "images = [cv2.imread(image_file) for image_file in image_files]\n",
      "\n",
      "# Stitch the images\n",
      "panorama = stitch_images(images)\n",
      "\n",
      "# Save or display the panorama\n",
      "cv2.imwrite('panorama.jpg', panorama)\n",
      "# cv2.imshow('Panorama', panorama)\n",
      "# cv2.waitKey(0)\n",
      "# cv2.destroyAllWindows()\n",
      "```\n",
      "\n",
      "This script uses SIFT for feature detection and description, FLANN based matcher for finding matches, and averages overlapping areas for blending. Note that the blending part is quite basic and might not produce perfect results for all sets of images. For better blending results, you might want to explore more sophisticated techniques like multi-band blending.\n",
      "\n",
      "Remember, the success of image stitching highly depends on the overlap between images, the presence of distinguishable features, and the similarity of image exposures and conditions.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "I'm coding in python and using the OpenCV library. Give me a python script to stitch 4 images together to create a panorama image. Use the following steps if you can:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa09e5-a48d-49ba-8e6c-a782d1077183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
